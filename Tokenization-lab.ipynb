{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bebace",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e74e9b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import timeit\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7404e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Provide historical context or background information where relevant.\n",
      "Aim for a well-rounded and insightful response, keeping in mind the diversity in audience knowledge.- Your target audience consists of experts with great familiarity.\n",
      "- Focus solely on the current state and future implications of the subject.- Write in a balanced tone, mixing formality with accessibility.\n",
      "- Compare and contrast different theories, methodologies, or viewpoints within the subject.\n",
      "You will be graded on how complete and appropriate your response is.- Provide historical context or background information where relevant.\n",
      "You will be graded on how complete and appropriate your response is.- Your target audience consists of beginners with no familiarity of the subject.\n",
      "Strive for completeness and appropriateness in your response, keeping in mind the diversity of the audience.- Your target audience consists of beginners with no familiarity of the subject.\n",
      "- Adopt a conversational and informal style to make the content accessible.\n",
      "- Compare and contrast different theories, methodologies, or viewpoints within the subject.\n",
      "Aim for a well-rounded and insightful response, keeping in mind the diversity in audience knowledge.- Provide historical context or background information where relevant.\n",
      "You will be graded on how complete and appropriate your response is.- Adopt a conversational and informal style to make the content accessible.\n",
      "- Provide historical context or background information where relevant.\n",
      "- Keep the content concise and to the point.\n",
      "You will be graded on how complete and appropriate your response is.- Focus solely on the current state and future implications of the subject.\n",
      "- Keep the content concise and to the point.\n",
      "You will be graded on how complete and appropriate your response is.- Focus solely on the current state and future implications of the subject.\n"
     ]
    }
   ],
   "source": [
    "# Download data for your choice of year (1810 to 1963)\n",
    "dataset = load_dataset(\"emrgnt-cmplxty/sciphi-textbooks-are-all-you-need\")\n",
    "\n",
    "# Specify the split you want (e.g., 'train')\n",
    "split_name = 'train'\n",
    "\n",
    "# Access the dataset for the specified split\n",
    "dataset_split = dataset[split_name]\n",
    "\n",
    "\n",
    "##\\\n",
    "my_rows = ''\n",
    "\n",
    "# Get the first 10 rows from that split (you can change the number as needed)\n",
    "# Instantiate a counter variable (start counting from 0)\n",
    "i = 0\n",
    "\n",
    "# Loop through each row of data in the specified split\n",
    "for notes in dataset_split:\n",
    "    # Print the current row\n",
    "    my_rows += notes.get('notes')\n",
    "\n",
    "    # Increase the counter by 1 to keep track of how many rows we've processed\n",
    "    i += 1\n",
    "\n",
    "    # Check if we've printed enough rows (e.g., 10 rows)\n",
    "    if i >= 10:  # Change 10 to the desired number of rows\n",
    "        # If we have printed enough rows, exit the loop (stop printing)\n",
    "        break\n",
    "        \n",
    "print(my_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "def16b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Provide historical context or background information where relevant.\n",
      "Aim for a well rounded and insightful response, keeping in mind the diversity in audience knowledge.  Your target audience consists of experts with great familiarity.\n",
      "  Focus solely on the current state and future implications of the subject.  Write in a balanced tone, mixing formality with accessibility.\n",
      "  Compare and contrast different theories, methodologies, or viewpoints within the subject.\n",
      "You will be graded on how complete and appropriate your response is.  Provide historical context or background information where relevant.\n",
      "You will be graded on how complete and appropriate your response is.  Your target audience consists of beginners with no familiarity of the subject.\n",
      "Strive for completeness and appropriateness in your response, keeping in mind the diversity of the audience.  Your target audience consists of beginners with no familiarity of the subject.\n",
      "  Adopt a conversational and informal style to make the content accessible.\n",
      "  Compare and contrast different theories, methodologies, or viewpoints within the subject.\n",
      "Aim for a well rounded and insightful response, keeping in mind the diversity in audience knowledge.  Provide historical context or background information where relevant.\n",
      "You will be graded on how complete and appropriate your response is.  Adopt a conversational and informal style to make the content accessible.\n",
      "  Provide historical context or background information where relevant.\n",
      "  Keep the content concise and to the point.\n",
      "You will be graded on how complete and appropriate your response is.  Focus solely on the current state and future implications of the subject.\n",
      "  Keep the content concise and to the point.\n",
      "You will be graded on how complete and appropriate your response is.  Focus solely on the current state and future implications of the subject.\n"
     ]
    }
   ],
   "source": [
    "#remove new line and other formatting characters\n",
    "for char in [\"-\"]:\n",
    "    my_rows = my_rows.replace(char, \" \")\n",
    "print(my_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57778071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " 'Provide',\n",
       " 'historical',\n",
       " 'context',\n",
       " 'or',\n",
       " 'background',\n",
       " 'information',\n",
       " 'where',\n",
       " 'relevant.\\nAim',\n",
       " 'for',\n",
       " 'a',\n",
       " 'well',\n",
       " 'rounded',\n",
       " 'and',\n",
       " 'insightful',\n",
       " 'response,',\n",
       " 'keeping',\n",
       " 'in',\n",
       " 'mind']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#this is a magic function to determine how long a cell takes to run. \n",
    "#It MUST be the first thing in a cell\n",
    "\n",
    "#split the whole string on spaces. This returns a list\n",
    "whitespace_tokens = my_rows.split(' ')\n",
    "\n",
    "#check the list\n",
    "whitespace_tokens[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0db8f4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Jonathan\n",
      "[nltk_data]     A\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Jonathan\n",
      "[nltk_data]     A\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "#This lemmatizer is based on the Morphy project above\n",
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "#Uncomment these two lines - you may need to download these, maybe not. \n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "wn_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1dd8000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.08 s\n",
      "Wall time: 1.11 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " 'Provide',\n",
       " 'historical',\n",
       " 'context',\n",
       " 'or',\n",
       " 'background',\n",
       " 'information',\n",
       " 'where',\n",
       " 'relevant.\\nAim',\n",
       " 'for',\n",
       " 'a',\n",
       " 'well',\n",
       " 'rounded',\n",
       " 'and',\n",
       " 'insightful',\n",
       " 'response,',\n",
       " 'keeping',\n",
       " 'in',\n",
       " 'mind']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#first we have to split the string on spaces to get \"words\"\n",
    "whitespace_tokens = my_rows.split(' ')\n",
    "\n",
    "my_lemmas = []\n",
    "for word in whitespace_tokens:\n",
    "    w = wn_lemmatizer.lemmatize(word)\n",
    "    my_lemmas.append(w)\n",
    "my_lemmas[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c526614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bpe\n",
      "  Downloading bpe-1.0-py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: pytest in c:\\users\\jonathan a\\anaconda3\\lib\\site-packages (from bpe) (7.1.2)\n",
      "Collecting hypothesis\n",
      "  Downloading hypothesis-6.87.1-py3-none-any.whl (420 kB)\n",
      "     -------------------------------------- 420.7/420.7 kB 8.7 MB/s eta 0:00:00\n",
      "Collecting mypy\n",
      "  Downloading mypy-1.5.1-cp310-cp310-win_amd64.whl (8.9 MB)\n",
      "     ---------------------------------------- 8.9/8.9 MB 38.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: toolz in c:\\users\\jonathan a\\anaconda3\\lib\\site-packages (from bpe) (0.12.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jonathan a\\anaconda3\\lib\\site-packages (from bpe) (4.64.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\jonathan a\\anaconda3\\lib\\site-packages (from bpe) (3.7)\n",
      "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in c:\\users\\jonathan a\\anaconda3\\lib\\site-packages (from hypothesis->bpe) (2.4.0)\n",
      "Collecting exceptiongroup>=1.0.0\n",
      "  Downloading exceptiongroup-1.1.3-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\jonathan a\\anaconda3\\lib\\site-packages (from hypothesis->bpe) (22.1.0)\n",
      "Collecting mypy-extensions>=1.0.0\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\jonathan a\\anaconda3\\lib\\site-packages (from mypy->bpe) (4.4.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in c:\\users\\jonathan a\\anaconda3\\lib\\site-packages (from mypy->bpe) (2.0.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\jonathan a\\anaconda3\\lib\\site-packages (from nltk->bpe) (1.1.1)\n",
      "Requirement already satisfied: click in c:\\users\\jonathan a\\anaconda3\\lib\\site-packages (from nltk->bpe) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jonathan a\\anaconda3\\lib\\site-packages (from nltk->bpe) (2022.7.9)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\jonathan a\\anaconda3\\lib\\site-packages (from pytest->bpe) (1.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\jonathan a\\anaconda3\\lib\\site-packages (from pytest->bpe) (22.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in c:\\users\\jonathan a\\anaconda3\\lib\\site-packages (from pytest->bpe) (1.0.0)\n",
      "Requirement already satisfied: py>=1.8.2 in c:\\users\\jonathan a\\anaconda3\\lib\\site-packages (from pytest->bpe) (1.11.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\jonathan a\\anaconda3\\lib\\site-packages (from pytest->bpe) (1.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jonathan a\\anaconda3\\lib\\site-packages (from pytest->bpe) (0.4.6)\n",
      "Installing collected packages: mypy-extensions, exceptiongroup, mypy, hypothesis, bpe\n",
      "  Attempting uninstall: mypy-extensions\n",
      "    Found existing installation: mypy-extensions 0.4.3\n",
      "    Uninstalling mypy-extensions-0.4.3:\n",
      "      Successfully uninstalled mypy-extensions-0.4.3\n",
      "Successfully installed bpe-1.0 exceptiongroup-1.1.3 hypothesis-6.87.1 mypy-1.5.1 mypy-extensions-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb7c332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bpe import Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e467d10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 2.01 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "whitespace_tokens = my_rows.split(' ')\n",
    "\n",
    "# calling the Encoder algorithm\n",
    "# we've specified 100 token vocab and 95% to be tokenized\n",
    "# the other 5% is transformed into UNK\n",
    "encoder = Encoder(100, pct_bpe=0.95)\n",
    "encoder.fit(whitespace_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0618fa5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provide historical conte__unkt or background information where relevant . aim for a well rounded and insightful response , keeping in mind the diversity in audience knowledge . your target audience consists of e__unkperts with great familiarity . focus solely on the current state and future implications of the subject . write in a balanced tone , mi__unking formality with accessibility . compare and contrast different theories , methodologies , or viewpoints within the subject . you will be graded on how complete and appropriate your response is . provide historical conte__unkt or background information where relevant . you will be graded on how complete and appropriate your response is . your target audience consists of beginners with no familiarity of the subject . strive for completeness and appropriateness in your response , keeping in mind the diversity of the audience . your target audience consists of beginners with no familiarity of the subject . adopt a conversational and informal style to make the content accessible . compare and contrast different theories , methodologies , or viewpoints within the subject . aim for a well rounded and insightful response , keeping in mind the diversity in audience knowledge . provide historical conte__unkt or background information where relevant . you will be graded on how complete and appropriate your response is . adopt a conversational and informal style to make the content accessible . provide historical conte__unkt or background information where relevant . keep the content concise and to the point . you will be graded on how complete and appropriate your response is . focus solely on the current state and future implications of the subject . keep the content concise and to the point . you will be graded on how complete and appropriate your response is . focus solely on the current state and future implications of the subject .\n"
     ]
    }
   ],
   "source": [
    "#print(encoder.tokenize(my_articles))\n",
    "\n",
    "print(next(encoder.inverse_transform(encoder.transform([my_rows]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def8b759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
